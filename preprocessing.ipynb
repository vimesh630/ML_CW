{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lwvIS8AbAgsAJC6zM8KK2XzDvMwuRji7",
      "authorship_tag": "ABX9TyO//pzJgbEt09HdQHZ46BWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vimesh630/ML_CW/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "73X4nH9_ooGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f_V08h1os24",
        "outputId": "8c51351c-3cb2-4157-b904-3f145bc3b59a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "Ia3nWJBIouxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "BFviatRooxqz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Datasets"
      ],
      "metadata": {
        "id": "GCNc_fKyo2hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets from Google Drive\n",
        "file_path_full = '/content/drive/MyDrive/ML Coursework/bank+marketing/bank-additional/bank-additional/bank-additional-full.csv'\n",
        "file_path_subset = '/content/drive/MyDrive/ML Coursework/bank+marketing/bank-additional/bank-additional/bank-additional.csv'\n",
        "\n",
        "# Load both datasets\n",
        "df_full = pd.read_csv(file_path_full, sep=';')\n",
        "df_subset = pd.read_csv(file_path_subset, sep=';')\n",
        "\n",
        "# Check if both datasets have the same structure\n",
        "if df_full.columns.equals(df_subset.columns):\n",
        "    print(\"Both datasets have the same structure. Merging...\")\n",
        "    df = pd.concat([df_full, df_subset], ignore_index=True)\n",
        "else:\n",
        "    print(\"Datasets have different structures. Using `bank-additional-full.csv` for preprocessing.\")\n",
        "    df = df_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMTA7YYSo4s6",
        "outputId": "07351c37-636d-4cde-a98d-4b8579bed76a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both datasets have the same structure. Merging...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Missing or Unknown Data"
      ],
      "metadata": {
        "id": "UMh5ow9do9WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"unknown\" with NaN and handle missing values\n",
        "df.replace('unknown', np.nan, inplace=True)\n",
        "\n",
        "# Drop columns with more than 30% missing values (adjust threshold if needed)\n",
        "missing_threshold = 0.3\n",
        "missing_percentage = df.isnull().mean()\n",
        "columns_to_drop = missing_percentage[missing_percentage > missing_threshold].index\n",
        "df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "# Fill remaining missing values\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)  # Fill categorical columns with mode\n",
        "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)  # Fill numeric columns with mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Dr6BXBpDCC",
        "outputId": "c374dd78-14e4-4eab-e1b3-ff83151257c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-78c3930e0f85>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)  # Fill categorical columns with mode\n",
            "<ipython-input-4-78c3930e0f85>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mean(), inplace=True)  # Fill numeric columns with mean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode Categorical Variables"
      ],
      "metadata": {
        "id": "lZTcj3OKpFS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables using LabelEncoder\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save encoders for future use"
      ],
      "metadata": {
        "id": "KEHisACvpJFv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale Numerical Features"
      ],
      "metadata": {
        "id": "3M5mi9dbpLHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale numeric features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('y')\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
      ],
      "metadata": {
        "id": "hV4xadRSpOXH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balance the Dataset"
      ],
      "metadata": {
        "id": "dMd1zFAHpRC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "# Check target distribution\n",
        "print(\"Target distribution before balancing:\", y.value_counts())\n",
        "\n",
        "# Use SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Check new target distribution\n",
        "print(\"Target distribution after balancing:\", np.bincount(y_resampled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q4UFFvlo_3A",
        "outputId": "e7fd2f70-ab8b-4b30-bfee-86e98bdc9d2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target distribution before balancing: y\n",
            "0    40216\n",
            "1     5091\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target distribution after balancing: [40216 40216]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Dataset"
      ],
      "metadata": {
        "id": "dEBOXsr_pV0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ph8-9HQppYij"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Preprocessed Data"
      ],
      "metadata": {
        "id": "yvZmy5EMpbIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessed data to Google Drive\n",
        "preprocessed_data_path_train = '/content/drive/My Drive/ML Coursework/Preprocessed Dataset/train_data.csv'\n",
        "preprocessed_data_path_test = '/content/drive/My Drive/ML Coursework/Preprocessed Dataset/test_data.csv'\n",
        "\n",
        "# Save training and testing data\n",
        "pd.concat([X_train, y_train], axis=1).to_csv(preprocessed_data_path_train, index=False)\n",
        "pd.concat([X_test, y_test], axis=1).to_csv(preprocessed_data_path_test, index=False)\n",
        "\n",
        "print(f\"Preprocessed training data saved to: {preprocessed_data_path_train}\")\n",
        "print(f\"Preprocessed testing data saved to: {preprocessed_data_path_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufHuRIXppfVQ",
        "outputId": "8cef8ad2-6ac6-4fb3-87b1-6a94c98ca94a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed training data saved to: /content/drive/My Drive/ML Coursework/Preprocessed Dataset/train_data.csv\n",
            "Preprocessed testing data saved to: /content/drive/My Drive/ML Coursework/Preprocessed Dataset/test_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify Preprocessed Data"
      ],
      "metadata": {
        "id": "fSHEYuuLpjub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the preprocessed training data\n",
        "print(\"Sample of preprocessed training data:\")\n",
        "print(pd.concat([X_train, y_train], axis=1).head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y25LGAMpmS7",
        "outputId": "84837268-6e57-4300-81b0-10ea6976409f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of preprocessed training data:\n",
            "            age       job   marital  education   default   housing      loan  \\\n",
            "30576 -0.579390  0.945251 -0.280414   0.620221 -0.009397  0.907476  2.356668   \n",
            "8588  -0.867539 -0.744768 -1.938341  -0.820256 -0.009397  0.907476  2.356668   \n",
            "43947 -1.155688  0.945251 -1.938341  -0.340097 -0.009397 -1.101957  2.356668   \n",
            "79182 -0.865009  1.508591  1.373147   0.620221 -0.009397  0.907476 -0.424328   \n",
            "73911 -1.900053  1.226921  1.377514   1.010280 -0.009397 -0.976271 -0.424328   \n",
            "\n",
            "        contact     month  day_of_week  ...  campaign     pdays  previous  \\\n",
            "30576 -0.757217  0.760470    -0.719562  ...  0.158113  0.195930 -0.349533   \n",
            "8588   1.320625 -0.102081     1.428221  ... -0.205228  0.195930 -0.349533   \n",
            "43947 -0.757217 -0.533357    -1.435490  ... -0.205228  0.195930 -0.349533   \n",
            "79182 -0.757217  1.621886    -1.433604  ... -0.205228  0.195930 -0.349533   \n",
            "73911 -0.757217  0.760470     0.757074  ... -0.227955 -5.119789  9.663307   \n",
            "\n",
            "       poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
            "30576  0.193599     -1.198669       -1.179930      -1.231926  -1.307303   \n",
            "8588   0.193599      0.839270        1.535684      -0.280585   0.716532   \n",
            "43947  0.193599      0.839270        0.590747      -0.475177   0.770155   \n",
            "79182  0.193599     -0.752869        1.771377      -1.946172  -1.527459   \n",
            "73911  2.942396     -1.198669        0.518192       0.108600  -1.687025   \n",
            "\n",
            "       nr.employed  y  \n",
            "30576    -0.937905  0  \n",
            "8588      0.844356  0  \n",
            "43947     0.844356  1  \n",
            "79182    -2.809969  1  \n",
            "73911    -2.186869  1  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    }
  ]
}